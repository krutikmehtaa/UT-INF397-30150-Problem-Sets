{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "___Chapter 10: Problem 7___\n",
        "\n",
        "Fit a neural network to the Default data. Use a single hidden layer with 10 units, and dropout regularization. Have a look at Labs 10.9.1-10.9.2 for guidance. Compare the classification performance of your model with that of linear logistic regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\kruti\\AppData\\Roaming\\Python\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from ISLP.models import ModelSpec as MS\n",
        "from ISLP.torch import SimpleDataModule, SimpleModule, ErrorTracker\n",
        "from pytorch_lightning import Trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load and preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "default = pd.read_csv(\"Default.csv\")\n",
        "default['default'] = pd.get_dummies(default['default'], drop_first=True).astype(int)\n",
        "default['student'] = pd.get_dummies(default['student'], drop_first=True).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Features, Target and Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = MS(default.columns.drop('default'), intercept=False)\n",
        "X = model.fit_transform(default).to_numpy()\n",
        "Y = default['default'].to_numpy()\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X, Y, test_size=1/3, random_state=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Logistic Regression - Baseline Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LOGISTIC REGRESSION\n",
            "\n",
            "Test Accuracy = 0.9763 (97.63%)\n"
          ]
        }
      ],
      "source": [
        "print(\"LOGISTIC REGRESSION\")\n",
        "print()\n",
        "\n",
        "def_clf = LogisticRegression(max_iter=1000).fit(X_train, Y_train)\n",
        "Yhat_class = def_clf.predict(X_test)\n",
        "lr_accuracy = accuracy_score(Y_test, Yhat_class)\n",
        "\n",
        "print(f\"Test Accuracy = {lr_accuracy:.4f} ({lr_accuracy*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Neural Networks - Prepare PyTorch datasets, Create Data Modules, Train and Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "C:\\Users\\kruti\\AppData\\Roaming\\Python\\Python313\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
            "\n",
            "  | Name  | Type             | Params | Mode \n",
            "---------------------------------------------------\n",
            "0 | model | Default          | 62     | train\n",
            "1 | loss  | CrossEntropyLoss | 0      | train\n",
            "---------------------------------------------------\n",
            "62        Trainable params\n",
            "0         Non-trainable params\n",
            "62        Total params\n",
            "0.000     Total estimated model params size (MB)\n",
            "8         Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NEURAL NETWORK (10 hidden units, 0.4 dropout)\n",
            "\n",
            "Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:01<00:00, 106.99it/s, v_num=1]       "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [00:01<00:00, 106.63it/s, v_num=1]\n",
            "Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:00<00:00, 531.10it/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\">        Test metric        </span>â”ƒ<span style=\"font-weight: bold\">       DataLoader 0        </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">       test_accuracy       </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">     0.970005989074707     </span>â”‚\n",
              "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.13501016795635223    </span>â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚\u001b[36m \u001b[0m\u001b[36m      test_accuracy      \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m    0.970005989074707    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
              "â”‚\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.13501016795635223   \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test Accuracy: 0.9700 (97.00%)\n",
            "Test Loss: 0.1350\n"
          ]
        }
      ],
      "source": [
        "print(\"NEURAL NETWORK (10 hidden units, 0.4 dropout)\")\n",
        "print()\n",
        "\n",
        "# Define neural network architecture\n",
        "class Default(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(Default, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.sequential = nn.Sequential(\n",
        "            nn.Linear(input_size, 10),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(10, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        return self.sequential(x)\n",
        "    \n",
        "X_train_t = torch.tensor(X_train.astype(np.float32))\n",
        "Y_train_t = torch.tensor(Y_train.astype(np.int64))\n",
        "def_train = TensorDataset(X_train_t, Y_train_t)\n",
        "\n",
        "X_test_t = torch.tensor(X_test.astype(np.float32))\n",
        "Y_test_t = torch.tensor(Y_test.astype(np.int64))\n",
        "def_test = TensorDataset(X_test_t, Y_test_t)\n",
        "\n",
        "def_dm = SimpleDataModule(\n",
        "    def_train,\n",
        "    def_test,\n",
        "    batch_size=32,\n",
        "    num_workers=4,\n",
        "    validation=def_test\n",
        ")\n",
        "\n",
        "def_model = Default(X.shape[1])\n",
        "def_module = SimpleModule.classification(def_model, num_classes=2)\n",
        "\n",
        "def_trainer = Trainer(\n",
        "    max_epochs=50,\n",
        "    log_every_n_steps=5,\n",
        "    callbacks=[ErrorTracker()],\n",
        "    enable_progress_bar=True\n",
        ")\n",
        "\n",
        "def_trainer.fit(def_module, datamodule=def_dm)\n",
        "\n",
        "test_results = def_trainer.test(def_module, datamodule=def_dm)\n",
        "nn_accuracy = test_results[0]['test_accuracy']\n",
        "nn_loss = test_results[0]['test_loss']\n",
        "\n",
        "print(f\"\\nTest Accuracy: {nn_accuracy:.4f} ({nn_accuracy*100:.2f}%)\")\n",
        "print(f\"Test Loss: {nn_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Accuracy: 0.9763 (97.63%)\n",
            "Neural Network Accuracy:      0.9700 (97.00%)\n",
            "\n",
            "\n",
            "Difference: 0.63 percentage points\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"Logistic Regression Accuracy: {lr_accuracy:.4f} ({lr_accuracy*100:.2f}%)\")\n",
        "print(f\"Neural Network Accuracy:      {nn_accuracy:.4f} ({nn_accuracy*100:.2f}%)\")\n",
        "\n",
        "print()\n",
        "\n",
        "print(f\"\\nDifference: {(lr_accuracy - nn_accuracy)*100:.2f} percentage points\")\n",
        "\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conclusion: The logistic regression model performs slightly better on this dataset, suggesting that the relationship is primarily linear and doesn't require the added complexity of a neural network."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
